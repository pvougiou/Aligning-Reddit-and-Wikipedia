{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inspecting the Aligned Dataset</h2>\n",
    "<p>We will be inspecting the dataset of aligned Reddit sequences of comments and Wikipedia sentences. The respective HDF5 files (i.e. `reddit.h5` and `wikipedia.h5`) are built in such a way that each sequence of comments on Reddit is aligned with 20 Wikipedia sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We are loading the `reddit.h5` and `wikipedia.h5` that contain the respective sequences of Reddit comments and Wikipedia sentences, aligned with each other. In those files, each word is represented by its position in the shared dictionary. We are loading that shared dictionary (i.e. `dictionary.json`) that will allow us to get the actual word given its position.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit_path = 'Aligned-Dataset/reddit.h5'\n",
    "wikipedia_path = 'Aligned-Dataset/wikipedia.h5'\n",
    "dictionary_path = 'Aligned-Dataset/dictionary.json'\n",
    "\n",
    "reddit = h5py.File(reddit_path, 'r')\n",
    "wikipedia = h5py.File(wikipedia_path, 'r')\n",
    "\n",
    "with open(dictionary_path, 'r') as f:\n",
    "    dictionary = json.load(f, 'utf-8')\n",
    "    id2word = dictionary['id2word']\n",
    "    id2word = {int(key): id2word[key] for key in id2word}\n",
    "    word2id = dictionary['word2id']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def capitalise(string):\n",
    "    if string[0] == 't':\n",
    "        string = 'T'\n",
    "    else:\n",
    "        string[0] = 'V'\n",
    "    return \n",
    "\n",
    "def getAligned(index, dataset = 'train'):\n",
    "    if dataset == 'train' or dataset == 'test' or dataset == 'validate':\n",
    "        if index < len(reddit[dataset]):\n",
    "            i = 0\n",
    "            sequence = ''\n",
    "            while reddit[dataset][index][i + 1] != word2id['<PAD>']:\n",
    "                if reddit[dataset][index][i] == word2id['<end>'] or reddit[dataset][index][i] == word2id['<eot>']:\n",
    "                    sequence = sequence + id2word[reddit[dataset][index][i]].encode('utf-8', 'ignore') + '\\n'\n",
    "                else:\n",
    "                    sequence = sequence + id2word[reddit[dataset][index][i]].encode('utf-8', 'ignore') + ' '\n",
    "                i += 1\n",
    "            sequence = sequence + id2word[reddit[dataset][index][i]].encode('utf-8', 'ignore')\n",
    "            sentences = []\n",
    "            for j in range(0, 20):\n",
    "                i = 0\n",
    "                sentences.append('')\n",
    "                while wikipedia[dataset][index * 20 + j][i + 1] != word2id['<PAD>']:\n",
    "                    sentences[j] += id2word[wikipedia[dataset][index * 20 + j][i]].encode('utf-8', 'ignore') + ' '\n",
    "                    i += 1\n",
    "                sentences[j] += id2word[wikipedia[dataset][index * 20 + j][i]].encode('utf-8', 'ignore')\n",
    "\n",
    "            print ('Number: %d Sequence of Comments from the %s Set\\n' % (index, dataset.title()))\n",
    "            print (sequence)\n",
    "            print ('\\n\\nWikipedia Sentences for the Number: %d Sequence of Comments from the %s Set\\n' % (index, dataset.title()))\n",
    "\n",
    "            print ('\\n'.join(sentences))\n",
    "        else:\n",
    "            print ('The index exceeds the available examples in the %s Set.' % (dataset.title()))\n",
    "            print ('Pick an index between 0 and %d for the %s Set.' % (len(reddit[dataset]) - 1, dataset.title()))\n",
    "    else:\n",
    "        print('The available options for the dataset variable are: train, validation and test.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>By running the `getAligned(i, dataset)` function we are printing the $i$-th sequence of comments along with the 20 Wikipedia sentences with which it is aligned. The dataset is split into training, validation and test with respective portions of 80, 10 and 10 that result in the following options for the `dataset` variable: </p>\n",
    "* `train` containing 11248 sequences of comments along with 224960 sentences\n",
    "* `validation` containing 1406 sequences of comments along with 28100 sentences\n",
    "* `test` containing 1406 sequences of comments along with 28100 sentences\n",
    "\n",
    "<br>The `<sot>` and `<eot>` are the start-of-title and end-of-title tokens of each sequence. Each comment in a sequence is augmented with start-of-comment `<start>` and end-of-comment `<end>` tokens.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 256 Sequence of Comments from the Validate Set\n",
      "\n",
      "<sot> TIL Michael Crichton , author of Jurassic Park , felt his literature professor at Harvard was giving him unfair grades . To prove it , he turned in a paper by George Orwell and received a B- <eot>\n",
      "<start> <end>\n",
      "<start> I broke my wrist in college and forgot about a paper that was due , so I just printed out a paper I did in high school . In HS , I got a B- on the paper . In College , I got an A . I always thought my high school teacher was too harsh , and felt that it was proven with my self-plagiarism in college . <end>\n",
      "<start> I did at least 5 book reports on Gary NaN The Hatchet . <end>\n",
      "<start> If you did that many book reports on it how can you not know it is just \" Hatchet \" , not \" The Hatchet \" ? ( Never read it myself , but helped my daughter with her book report on it last fall ) <end>\n",
      "<start> Because it was nearly 20 years ago . <end>\n",
      "<start> Also , the ( very famous ) book is almost universally known as The Hatchet in popular culture . This is similar to a lot of bands , like Dead Kennedys and Eagles , who almost always get a \" the \" in front of their names , even though it's not technically part of the name and never appears on [ album ] [ covers ]\n",
      "\n",
      "\n",
      "Wikipedia Sentences for the Number: 256 Sequence of Comments from the Validate Set\n",
      "\n",
      "and tends to analyze issues in those terms .\n",
      "NaN usually focus on community , society , or nation .\n",
      "It is used and has been used as an element in many different and diverse types of government and political , economic and educational philosophies throughout history and all human societies in practice contain elements of both individualism and collectivism .\n",
      "Collectivism can be divided into horizontal collectivism and vertical collectivism .\n",
      "Horizontal collectivism stresses collective decision-making among relatively equal individuals , and is thus usually based on decentralization .\n",
      "Vertical collectivism is based on hierarchical structures of power and on moral and cultural conformity , and is therefore based on centralization .\n",
      "A cooperative enterprise would be an example of horizontal collectivism , whereas a military hierarchy would be an example of vertical collectivism .\n",
      "The British Independent Labour Party sent a small contingent to fight in the Spanish Civil War .\n",
      "The contingent fought alongside the Workers \" Party of Marxist Unification ( POUM ) and included George Orwell , who subsequently wrote about his experiences in his personal account Homage to Catalonia .\n",
      "Social chauvinism can be described as aggressive or fanatical patriotism , particularly during time of war , in support of one's own nation ( e . g . ,\n",
      "government , culture , etc . )\n",
      "versus other nation ( s ) , displayed by those who are socialists or social democrats .\n",
      "During World War I , most left-wing political parties took a NaN stand , with few exceptions .\n",
      "Most Socialists gave up their anti-militarism and their belief in international unity among the working class in favour of 'defense of the fatherland \" , and turned to social-chauvinism , most notably the German Social Democratic Party and the French Socialist Party .\n",
      "The consequence of this policy on labor relations within the combatant countries was something called NaN in Germany , a term deriving from the medieval concept of \" peace ( especially between feuding families ) within a besieged city \" .\n",
      "Other countries had their own terms .\n",
      "By this means , strikes and other forms of industrial action were ended for the duration .\n",
      "When they re-emerged after the First World War , compounded with the example of the Bolsheviks in winning a revolution , a longing for the conditions which had transpired during the war was a major motivation for fascism .\n",
      "It is this concept which lies behind the first motto of the tripartite series of George Orwell in his novel which was published in 1949 , titled Nineteen Eighty-Four : War is Peace .\n",
      "His imaginary society keeps itself from NaN protest by constantly being at war .\n"
     ]
    }
   ],
   "source": [
    "getAligned(256, dataset = 'validate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
